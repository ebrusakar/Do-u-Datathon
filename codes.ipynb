{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ae79ac",
   "metadata": {},
   "source": [
    "# Doğuş Datathon - Zingat / Coderspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Timestamp\n",
    "from ggplot import *\n",
    "import pandas\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from matplotlib import pyplot\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize': (12.0, 8.0)})\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "train = pd.read_csv(\"Adsızz.csv\")\n",
    "real_test = pd.read_csv(\"real_test2.csv\")\n",
    "\n",
    "train.iloc[:,[0,1]].head()\n",
    "for col in train.columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include='all')\n",
    "real_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20083dd",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning Categorical Features \n",
    "\n",
    "train.path = train.path.apply(lambda x: 'Istanbul' if 'Istanbul' in x else x)    \n",
    "train.path = train.path.apply(lambda x: 'Izmir' if 'Izmir' in x else x) \n",
    "\n",
    "counts = train[\"path\"].value_counts()\n",
    "percent = train[\"path\"].value_counts(normalize=True)\n",
    "percent100 = train[\"path\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "pd.DataFrame({'counts': counts, 'per': percent, 'per100': percent100})\n",
    "\n",
    "#Binning Categorical Features\n",
    "\n",
    "real_test.path = real_test.path.apply(lambda x: 'Istanbul' if 'Istanbul' in x else x)    \n",
    "real_test.path = real_test.path.apply(lambda x: 'Izmir' if 'Izmir' in x else x) \n",
    "\n",
    "counts = real_test[\"path\"].value_counts()\n",
    "percent = real_test[\"path\"].value_counts(normalize=True)\n",
    "percent100 = real_test[\"path\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "pd.DataFrame({'counts': counts, 'per': percent, 'per100': percent100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c93de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tarih_epoch = pd.to_datetime(train['tarih']) - pd.datetime(2018, 1, 1)\n",
    "train['tarih'] = tarih_epoch.dt.days\n",
    "\n",
    "tarih_epoch = pd.to_datetime(real_test['tarih']) - pd.datetime(2018, 1, 1)\n",
    "real_test['tarih'] = tarih_epoch.dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96f4b8",
   "metadata": {},
   "source": [
    "Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = pd.DataFrame(train.isnull().sum().sort_values(ascending=False)[:25])\n",
    "nulls.columns = ['Null Count']\n",
    "nulls.index.name = 'Feature'\n",
    "nulls\n",
    "\n",
    "nulls2 = pd.DataFrame(real_test.isnull().sum().sort_values(ascending=False)[:25])\n",
    "nulls2.columns = ['Null Count']\n",
    "nulls2.index.name = 'Feature'\n",
    "nulls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1646b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train[\"manzara\"]\n",
    "del train[\"otopark\"]\n",
    "train = train.fillna(train.mode().iloc[0])                 #Replace missing values with the most frequent value\n",
    "nulls = pd.DataFrame(train.isnull().sum().sort_values(ascending=False)[:25])\n",
    "nulls.columns = ['Null Count']\n",
    "nulls.index.name = 'Feature'\n",
    "nulls\n",
    "\n",
    "\n",
    "del real_test[\"manzara\"]\n",
    "del real_test[\"otopark\"]\n",
    "real_test = real_test.fillna(real_test.mode().iloc[0])      #Replace missing values with the most frequent value\n",
    "nulls2 = pd.DataFrame(real_test.isnull().sum().sort_values(ascending=False)[:25])\n",
    "nulls2.columns = ['Null Count']\n",
    "nulls2.index.name = 'Feature'\n",
    "#nulls2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb2aa9",
   "metadata": {},
   "source": [
    "Removing and Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bb58f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_train = train._get_numeric_data()\n",
    "num_train.columns\n",
    "def var_summary(x):\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),  x.std(), x.var(), x.min(), x.quantile(0.01), x.quantile(0.05),x.quantile(0.10),x.quantile(0.25),x.quantile(0.50),x.quantile(0.75), x.quantile(0.90),x.quantile(0.95), x.quantile(0.99),x.max()], \n",
    "                  index=['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR', 'MIN', 'P1' , 'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,'MAX'])\n",
    "\n",
    "num_train.apply(lambda x: var_summary(x)).T\n",
    "\n",
    "sns.boxplot(train['guncel_fiyat']) \n",
    "sns.boxplot(train['brutmkare']) \n",
    "sns.boxplot(train['netmkare']) \n",
    "train['guncel_fiyat']= train['guncel_fiyat'].clip(upper=train['guncel_fiyat'].quantile(0.99)) \n",
    "train['brutmkare']= train['brutmkare'].clip(upper=train['brutmkare'].quantile(0.99)) \n",
    "train['netmkare']= train['netmkare'].clip(upper=train['netmkare'].quantile(0.99)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933dd1eb",
   "metadata": {},
   "source": [
    "Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "train['path'] = labelencoder.fit_transform(train['path'])\n",
    "train['emlaktipi'] = labelencoder.fit_transform(train['emlaktipi'])\n",
    "train['isitmatipi'] = labelencoder.fit_transform(train['isitmatipi'])\n",
    "real_test['path'] = labelencoder.fit_transform(real_test['path'])\n",
    "real_test['emlaktipi'] = labelencoder.fit_transform(real_test['emlaktipi'])\n",
    "real_test['isitmatipi'] = labelencoder.fit_transform(real_test['isitmatipi'])\n",
    "\n",
    "le_enc = preprocessing.LabelEncoder()\n",
    "le_enc = le_enc.fit(train[\"odasayisi\"])\n",
    "le_enc.classes_ = np.array([\"1+0\",\"1+1\",\"2+0\",\"2+1\",\"2+2\",\"3+1\",\"3+2\",\"4+1\",\"4+2\",\"4+3\",\"4+4\",\"5+1\",\"5+2\",\"5+3\",\"6+1\",\"6+2\",\n",
    "                            \"6+3\",\"7+1\",\"7+2\",\"7+3\",\"8+1\",\"8+2\",\"8+3\",\"8+4\",\"9+1\",\"9+2\",\"9+3\",\"9+4\",\"10+0\",\"10+1\",\"10+2\",\n",
    "                            \"10+3\",\"10+4\",\"1149+0\",\"11+3\",\"12+2\",\"19+4\",\"19+6\"])\n",
    "train[\"odasayisi\"] = le_enc.transform(train[\"odasayisi\"])\n",
    "le_enc = preprocessing.LabelEncoder()\n",
    "le_enc.classes_ = np.array([\"1+0\",\"1+1\",\"2+0\",\"2+1\",\"2+2\",\"3+1\",\"3+2\",\"4+1\",\"4+2\",\"4+3\",\"4+4\",\"5+1\",\"5+2\",\"5+3\",\"6+1\",\"6+2\",\n",
    "                            \"6+3\",\"7+1\",\"7+2\",\"7+3\",\"8+1\",\"8+2\",\"8+3\",\"8+4\",\"9+1\",\"9+2\",\"9+3\",\"9+4\",\"10+0\",\"10+1\",\"10+2\",\n",
    "                            \"10+3\",\"10+4\",\"1149+0\",\"11+3\",\"12+2\",\"19+4\",\"19+6\"])\n",
    "le_enc = le_enc.fit(real_test[\"odasayisi\"])\n",
    "real_test[\"odasayisi\"] = le_enc.transform(real_test[\"odasayisi\"])\n",
    "\n",
    "#Find and Replace\n",
    "preserved_mapper = {\"bulundugukat\": {'Kot 4':1 ,'Kot 3':1,'Kot 2':1,'Kot 1':1,'Bodrum Kat':1,'Zemin Kat':2,'Giris Kati':2,\n",
    "                    'Bahce kati':2,'Yuksek Giris': 2,'Mustakil':2 ,'Komple':2, '1':3,'2':4,'3':5,'4':6,'5': 7, '6': 8,\n",
    "                    '7': 9,'8': 10,'9': 11,'10': 12,'11': 13,'12': 14,'13': 15,'14': 16,'15': 17,'16': 18,'17': 19,'18': 20,\n",
    "                    '19': 21,'20': 22,'20 ve uzeri': 23,'cati Kati': 24,'En ust Kat': 24,'Teras Kat': 24}}     \n",
    "train = train.replace(preserved_mapper)  \n",
    "real_test = real_test.replace(preserved_mapper)\n",
    "\n",
    "preserved_mapper = {\"binadakikatsayisi\": {'1':1,'2':2,'3':3,'4':4,'5': 5, '6': 6, '7': 7,'8': 8,'9': 9,'10': 10,\n",
    "                                          '10-20 arasi': 15,'20 ve uzeri': 25}}     \n",
    "train = train.replace(preserved_mapper) \n",
    "real_test = real_test.replace(preserved_mapper)\n",
    "\n",
    "preserved_mapper = {\"binayasi\": {'0':0,'1':1,'2':2,'3':3,'4':4,'5': 5,'6-10 arasi':8,'11-15 arasi':13,'16-20 arasi':18,\n",
    "                                 '21-25 arasi':23,'26-30 arasi':28,'31-35 arasi':33,'36-40 arasi':38,'40 ve uzeri':45}}     \n",
    "train = train.replace(preserved_mapper)\n",
    "train.head() \n",
    "real_test = real_test.replace(preserved_mapper)\n",
    "real_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df,column_name):\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "\n",
    "train = create_dummies(train,\"emlaktipi\")\n",
    "real_test= create_dummies(train,\"emlaktipi\")\n",
    "train = create_dummies(train,\"path\")\n",
    "real_test= create_dummies(train,\"path\")\n",
    "\n",
    "del train[\"emlaktipi\"]\n",
    "del train[\"path\"]\n",
    "del real_test[\"emlaktipi\"]\n",
    "del real_test[\"path\"]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    " return 0 if x == 'YOK' else 1\n",
    "train['Interkom'] = train[\"Interkom\"].apply(encode)\n",
    "real_test['Interkom'] = real_test[\"Interkom\"].apply(encode)\n",
    "def encode(x):\n",
    " return 0 if x == 'YOK' else 1\n",
    "train['depremyonetmeligineuygun'] = train[\"depremyonetmeligineuygun\"].apply(encode)\n",
    "real_test['depremyonetmeligineuygun'] = real_test[\"depremyonetmeligineuygun\"].apply(encode)\n",
    "def encode(x):\n",
    " return 0 if x == 'YOK' else 1\n",
    "train['asansor'] = train[\"asansor\"].apply(encode)\n",
    "real_test['asansor'] = real_test[\"asansor\"].apply(encode)\n",
    "def encode(x):\n",
    " return 0 if x == 'YOK' else 1\n",
    "train['cocukoyunalani'] = train[\"cocukoyunalani\"].apply(encode)\n",
    "real_test['cocukoyunalani'] = real_test[\"cocukoyunalani\"].apply(encode)\n",
    "def encode(x):\n",
    " return 0 if x == 'YOK' else 1\n",
    "train['giyinmeodasi'] = train[\"giyinmeodasi\"].apply(encode)\n",
    "real_test['giyinmeodasi'] = real_test[\"giyinmeodasi\"].apply(encode)\n",
    "def encode(x):\n",
    " return 0 if x == 'YOK' else 1\n",
    "train['ebeveynbanyosu'] = train.ebeveynbanyosu.apply(encode)\n",
    "real_test['ebeveynbanyosu'] = real_test.ebeveynbanyosu.apply(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83d9b9",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=train[\"brutmkare\"],columns=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = train.select_dtypes(exclude=[np.number])\n",
    "categoricals.describe()\n",
    "numeric_features = train.select_dtypes(include=[np.number])\n",
    "numeric_features.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf002ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quality_pivot = train.pivot_table(index='banyosayisi',\n",
    "                  values='guncel_fiyat', aggfunc=np.median)\n",
    "quality_pivot.plot(kind='bar', color='blue')\n",
    "plt.xlabel('banyosayisi')\n",
    "plt.ylabel('guncel_fiyat')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "plt.scatter(x=train['netmkare'], y=train['guncel_fiyat'])\n",
    "plt.ylabel('guncel_fiyat')\n",
    "plt.xlabel('netmkare')\n",
    "plt.show()\n",
    "\n",
    "train = train[train['netmkare'] < 120000] #We will create a new dataframe with some outliers removed.\n",
    "plt.scatter(x=train['netmkare'], y=np.log(train[\"guncel_fiyat\"]))\n",
    "plt.xlim(-100,8000) # This forces the same scale as before\n",
    "plt.ylabel(\"guncel_fiyat\")\n",
    "plt.xlabel('netmkare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_pivot = train.pivot_table(index='bulundugukat', values='guncel_fiyat', aggfunc=np.median)\n",
    "condition_pivot.plot(kind='bar', color='blue')\n",
    "plt.xlabel('bulundugukat',fontsize=3)\n",
    "plt.ylabel('Median guncel_fiyat')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252d7ea",
   "metadata": {},
   "source": [
    "Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 14\n",
    "cols = num_corr.nlargest(k, 'guncel_fiyat')['guncel_fiyat'].index\n",
    "cm = np.corrcoef(num_train[cols].values.T)\n",
    "sns.set(font_scale=1.35)\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "hm=sns.heatmap(cm, annot = True,vmax =.8, yticklabels=cols.values, xticklabels = cols.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837cce7",
   "metadata": {},
   "source": [
    "# Checking Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7490e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(style='ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "print (\"Skew is:\", train[\"guncel_fiyat\"].skew())\n",
    "plt.hist(train[\"guncel_fiyat\"], color='blue')\n",
    "plt.show()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(211)\n",
    "x = (train[\"guncel_fiyat\"])\n",
    "prob = stats.probplot(x, dist=stats.norm, plot=ax1)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_title('Probplot against normal distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98315248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y =np.log(train['guncel_fiyat'])\n",
    "plt.figure(1); plt.title('Johnson SU')\n",
    "sns.distplot(y, kde=False, fit=stats.johnsonsu)\n",
    "plt.figure(2); plt.title('Normal')\n",
    "sns.distplot(y, kde=False, fit=stats.norm)\n",
    "plt.figure(3); plt.title('Log Normal')\n",
    "sns.distplot(y, kde=False, fit=stats.lognorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5657e6",
   "metadata": {},
   "source": [
    "# Handling Multi-Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "def calculate_vif_(X, thresh=10.0):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
    "                  '\\' at index: ' + str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X.iloc[:, variables]\n",
    "calculate_vif_(train[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd641e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library for VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "vif_X = train[features]\n",
    "calc_vif(vif_X)\n",
    "vif_X = train.drop(['netmkare','isitmatipi','guncel_fiyat','banyosayisi','emlak','tarih'], axis=1)\n",
    "calc_vif(vif_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d132ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['netmkare','isitmatipi','guncel_fiyat','banyosayisi','emlak','tarih'], axis=1)\n",
    "real_test = real_test.drop(['netmkare','isitmatipi','guncel_fiyat','banyosayisi','emlak','tarih'], axis=1)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "real_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b8b0e2",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"guncel_fiyat\"] = np.log1p(train[\"guncel_fiyat\"])               #normalization\n",
    "y = train['guncel_fiyat'].reset_index(drop=True)\n",
    "X_train = train.drop(['guncel_fiyat'], axis=1)\n",
    "X_test = real_test.drop(['guncel_fiyat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit = []                                                          #overfitting\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "X = X_train.drop(overfit, axis=1)\n",
    "X_test = X_test.drop(overfit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b39da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42) \n",
    "\n",
    "xgboost = XGBRegressor(learning_rate=0.1,n_estimators=1000,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(ridge)\n",
    "print(\"ridge: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lasso)\n",
    "print(\"lasso: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a83c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rf')\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "rf_model_full_data = rf_reg.fit(X, y)\n",
    "\n",
    "print('ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print('elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print('Lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c62b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, rf_model_full_data.predict(X)))                 # best prediction\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, ridge_model_full_data.predict(X)))\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, elastic_model_full_data.predict(X)))\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, gbr_model_full_data.predict(X)))\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, xgb_model_full_data.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.floor(np.expm1(rf_model_full_data.predict(X_test))).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
